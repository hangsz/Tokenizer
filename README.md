# 中文分词器

## 原发行版

### IK Analyzer介绍 
Google Code：https://code.google.com/archive/p/ik-analyzer/

    IK Analyzer 是一个开源的，基亍 java 语言开发的轻量级的中文分词工具包。从 2006年 12 月推出 1.0 版开始， IKAnalyzer 已经推出了 4 个大版本。最初，它是以开源项目Luence 为应用主体的，结合词典分词和文法分析算法的中文分词组件。 从 3.0 版本开始，IK 发展为面向 Java 的公用分词组件，独立亍 Lucene 项目，同时提供了对 Lucene 的默认优化实现。 在 2012 版本中，IK 实现了简单的分词歧义排除算法，标志着 IK 分词器从单纯的词典分词向模拟语义分词衍化。

### 特性
1. 采用了特有的“正向迭代最细粒度切分算法“，支持细粒度和智能分词两种切分模式；
2. 在系统环境：Core2 i7 3.4G双核，4G内存，window 7 64位， Sun JDK 1.6_29 64位 普通pc环境测试，IK2012具有160万字/秒（3000KB/S）的高速处理能力。
3. 2012版本的智能分词模式支持简单的分词排歧义处理和数量词合并输出。
4. 采用了多子处理器分析模式，支持：英文字母、数字、中文词汇等分词处理，兼容韩文、日文字符
5. 优化的词典存储，更小的内存占用。支持用户词典扩展定义。特别的，在2012版本，词典支持中文，英文，数字混合词语。

## 我的修改
1. 去掉了依托Luence的代码，保留纯java公用组件源码；
2. 根据官方API写了一个对语句进行分词的函数，可以直接用；
3. 修改 org/wltea/analyzer/cfg/DefaultConfig.java进行字典配置：
  - PATH_DIC_MAIN: 主字典路径
  - PATH_DIC_QUANTIFIER: 量词字典路径
  - FILE_NAME: 拓展词典配置文件路径